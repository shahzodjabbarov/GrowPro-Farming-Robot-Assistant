ğŸŒ± GrowPro â€“ Intelligent Farming Robot Assistant

GrowPro is an autonomous agricultural robot system designed to tackle modern farming challenges such as labor shortages, rising operational costs, and unpredictable environmental conditions.
The system integrates computer vision, deep learning, IoT sensors, and real-time user interfaces to deliver precision agriculture capabilities in both autonomous and manual modes.

ğŸšœ Key Features

ğŸ¤– Multi-mode operation (Autonomous / Manual / Follow)

ğŸ‘ï¸ Real-time computer vision for navigation and crop analysis

ğŸ§  YOLOv8-based AI detection for disease, ripeness, weeds, and crop counting

ğŸ›°ï¸ Hybrid navigation system (camera-based + sensor-based)

ğŸ–¥ï¸ Farmer-friendly GUI with visual maps and live camera feeds

ğŸŒ¦ï¸ Weather-aware decision support (API-integrated)

ğŸ§© System Architecture Overview
User Interface (Laptop)
        â†‘
   Socket Communication
        â†“
Server-Side Processing (AI / CV / Control)
        â†‘
   Video & Sensor Streams
        â†“
Robot-Side Execution (Motors / Sensors / Navigation)

ğŸ§± Hardware Components

Main Computer: Raspberry Pi 4 Model B (8GB RAM, active cooling)

Vision: Dual high-resolution cameras (navigation + crop analysis)

Sensors:

Ultrasonic distance sensors

IR line-following sensors

Soil humidity sensors

Actuation:

Four-wheel drive system

Servo motors (soil sampling)

Chassis:

Yahboom Raspbot (prototype)

Planned custom motor driver board (future)

ğŸ’» Software Stack

Language: Python

Computer Vision: OpenCV

AI / ML: YOLOv8 (Ultralytics)

UI Framework: Pygame

Communication: Socket-based video & command streaming

Operating System: Raspberry Pi OS / Linux

External APIs: WeatherAPI (farming condition alerts)

ğŸ“‚ Repository Structure
GROWPRO-FARMING-ROBOT-ASSISTANT/
â”‚
â”œâ”€â”€ robot_side/        # Code running on the robot (Raspberry Pi)
â”‚   â”œâ”€â”€ motor_control/ # Motors, ultrasonic, IR sensors
â”‚   â”œâ”€â”€ navigation/    # Lane detection & camera-based navigation
â”‚   â””â”€â”€ remote_net/    # Remote control & video streaming
â”‚
â”œâ”€â”€ server_side/       # High-level processing & AI
â”‚   â”œâ”€â”€ control/       # Command orchestration
â”‚   â”œâ”€â”€ cv_models/     # YOLO models, datasets (linked externally)
â”‚   â””â”€â”€ detection/    # Crop, fruit & disease detection logic
â”‚
â”œâ”€â”€ user_side/         # User-facing applications
â”‚   â”œâ”€â”€ application/  # Main GrowPro app
â”‚   â”œâ”€â”€ manual_control/
â”‚   â””â”€â”€ navigation_app/
â”‚
â”œâ”€â”€ media/             # Posters, diagrams, and media links
â”‚
â””â”€â”€ README.md

ğŸ§  Core Capabilities
1ï¸âƒ£ Multi-Mode Operation

Autonomous Mode

Pre-mapped navigation

AI-guided crop monitoring

Manual Mode

Real-time remote driving

Live video feedback

Follow Mode

Person tracking using YOLO + Hungarian Algorithm

Occlusion handling and ID consistency

2ï¸âƒ£ Detection & Analysis

ğŸŒ¿ Crop disease detection

ğŸ“ Ripeness classification

ğŸ’§ Dry spot & soil moisture recognition

ğŸ“Š Crop counting (yield estimation)

ğŸŒ± Weed detection

Supported crops:

Pumpkin (A / B)

Salad (A / B)

Strawberry (A / B)

3ï¸âƒ£ Navigation Systems
Outdoor Navigation

Camera-based lane detection

CLAHE contrast enhancement

Adaptive Canny edge detection

ROI masking (removes ~60% irrelevant pixels)

Indoor / Greenhouse Navigation

IR line-following sensors

Ultrasonic obstacle avoidance

Smooth proportional steering control

ğŸ§ª Technical Implementation
Computer Vision Pipeline
Image Capture
 â†’ CLAHE Enhancement
 â†’ Gaussian Blur (5Ã—5)
 â†’ Grayscale Conversion
 â†’ ROI Masking (60% background removed)
 â†’ Adaptive Canny Edge Detection
 â†’ Morphological Cleaning (3Ã—3)
 â†’ Lane Center Calculation
 â†’ Motor Command Generation

YOLOv8 Detection System

Model: YOLOv8 (custom-trained)

Classes: 6 crop categories

Confidence Threshold: 0.3 â€“ 0.65

Performance:

Frame skipping (YOLO every 3rd frame)

Resolution scaling

~30 FPS real-time processing

Context-aware inference:

Detection classes switch automatically based on selected crop

ğŸŒ Communication Architecture

Video Streaming

JPEG compression

Socket + pickle transmission

Port: 8491

Control Commands

Socket-based protocol

Port: 8490

Data Flow

Robot â†’ Server â†’ UI feedback loop

Latency Optimization

Frame dropping

Caching strategies

ğŸ–¥ï¸ User Interface Design
Multi-Page UI Flow

Field selection

Mode selection (Auto / Manual / Follow)

Crop selection

Function selection:

Disease

Ripeness

Weed

Moisture

Info

Weather dashboard

Visual Map Interface

Interactive farm map

Real-time robot position

Disease markers (numbered)

Live camera feed with YOLO overlays

Connection status indicators

âš™ï¸ Performance Optimizations

Multi-threaded architecture

Cached UI assets

Pre-rendered rotated sprites

Queue-based frame management

Selective inference execution

â˜ï¸ Data Management & Future Integration
Current

Local sensor logging

Image capture & annotation

Crop count records

Planned

Cloud analytics dashboard

Multi-farm aggregation

Predictive disease modeling

Automated irrigation integration

ğŸ† Impact & Benefits

â±ï¸ 70% reduction in manual inspection time

ğŸ©º 2â€“3 days earlier disease detection

ğŸ’§ Reduced water waste through precise moisture analysis

ğŸ“ˆ Data-driven farming decisions

ğŸ“¦ Modular & scalable system design

ğŸ”® Future Roadmap
Hardware

Custom motor driver board

360Â° vision system

LiDAR integration

Larger battery capacity

Software

Mobile companion app

Multi-robot coordination

Advanced disease prediction

Cloud-based dashboards

ğŸ“¸ Media & Demonstrations

ğŸ‘‰ See media/README.md
 for:

Build process videos

Demonstration videos

Seminar presentations

Posters and certifications
